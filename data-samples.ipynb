{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing tweets for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('./data/tweets_labeled.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crear_datasets(dataset, scenario):\n",
    "    \n",
    "    \"\"\" \n",
    "        This method is in charge of loading or creating the respective\n",
    "        datasets for each scenario. First it checks that the locations where \n",
    "        the files are saved exist, if not it creates them, then it checks if the \n",
    "        respective files already exist, if so it creates the dataset from the\n",
    "        reading of the respective file, if not, it creates the dataset from its \n",
    "        position and the state of the parameters.\n",
    "        \n",
    "        dataset (DataFrame) = original dataset containing all the data already arranged and ready to be used\n",
    "        scenario (int) = scenario for which datasets are to be generated or loaded \n",
    "        \n",
    "        return: three DataFrame Objects by a yield (data1, data2, data3) \"\"\"\n",
    "    \n",
    "    scenario = scenario-1\n",
    "    \n",
    "    scenarios = ['./data/scenario1/','./data/scenario2/','./data/scenario3/']\n",
    "    \n",
    "    for scene in scenarios:\n",
    "        if os.path.exists(scene):\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(scene)\n",
    "\n",
    "    datasets = ['dataset_30','dataset_60','dataset_100']\n",
    "    \n",
    "    if scenario>(len(scenarios)) or scenario<0:\n",
    "        return 0\n",
    "    \n",
    "    for i in range(len(datasets)):\n",
    "        set = datasets[i]\n",
    "        cadena = f\"{scenarios[scenario]}{set}.csv\"\n",
    "        \n",
    "        if os.path.exists(cadena):\n",
    "            #print(\"lo esta leyendo\")\n",
    "            yield pd.read_csv(cadena, sep = ',')\n",
    "            \n",
    "        else:\n",
    "            #print(\"lo esta creando\")\n",
    "            switch_percentage = {\n",
    "                0 : 0.3,\n",
    "                1 : 0.6,\n",
    "                2 : 1\n",
    "            }\n",
    "            \n",
    "            percentage = switch_percentage.get(i, 1)\n",
    "            \n",
    "            quantity = round(len(dataset)*percentage)\n",
    "            \n",
    "            dataset_s = dataset.sample(n=quantity)\n",
    "            \n",
    "            dataset_s.to_csv(cadena, index=True)\n",
    "            \n",
    "            yield dataset_s\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, data2, data3 = crear_datasets(tweets, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
